seed_everything: 42

model:
  class_path: models.jepa.JEPAWrapper
  init_args:
    dim: 384
    learning_rate: 5e-4
    loss_fn:
      class_path: torch.nn.MSELoss
    base_model: 
      class_path: models.jepa.SlotJEPA
      init_args:
        image_encoder_name: 'vit_small_patch14_dinov2.lvd142m'
        slot_attention:
          class_path: models.slot_attention.SA
          init_args:
            input_dim: ${.....dim}
            slot_dim: ${.....dim}
            n_slots: 7
            implicit: True
        feature_decoder:
          class_path: models.decoder.TransformerDecoder
          init_args:
            dim: ${...dim}
            depth: 4
            resolution: [16, 16]
        dim: ${...dim}
        predictor_depth: 4

data:
  class_path: dataset.clevrer.CLEVRER
  init_args:
    data_dir: ./data/clevrer
    num_workers: 7
    n_frames: 10
    batch_size: 1
    resolution: 224
    stride: 4

trainer:
  logger: 
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "semdec"
      save_dir: ./lightning_logs
  log_every_n_steps: 3
