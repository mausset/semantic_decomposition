seed_everything: 42

model:
  class_path: models.slot_autoencoder.SlotAE
  init_args:
    dim: 384 
    learning_rate: 5e-4
    warmup_steps: 500
    resolution: [224, 224]
    n_slots: [[9, 8], [7, 6, 5, 4, 3]]
    image_encoder_name: 'vit_small_patch14_reg4_dinov2.lvd142m'
    project_slots: True
    decode_strategy: all
    loss_fn: 
      class_path: torch.nn.MSELoss
    slot_attention_arch: sat
    slot_attention_args:
      input_dim: ${..dim}
      slot_dim: ${..dim}
      depth: 1
      n_iters: 5
      implicit: True
      sample_strategy: learned
    feature_decoder_args:
      dim: ${..dim}
      depth: 4
      resolution: [16, 16]

data:
  class_path: dataset.coco.COCO
  init_args:
    data_dir: ./data/coco/coco2017
    num_workers: 7
    batch_size: 2
    resolution: 224

trainer:
  accumulate_grad_batches: 16
  logger: 
    class_path: lightning.pytorch.loggers.WandbLogger
    init_args:
      project: "semdec"
      save_dir: ./lightning_logs
  val_check_interval: 0.01
  limit_val_batches: 1
  log_every_n_steps: 5
